{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anantbadal/PHY683/blob/main/221269_AnantBadal_Assignment-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c9e525e-3fbb-41a7-8647-284726ad353e",
      "metadata": {
        "id": "4c9e525e-3fbb-41a7-8647-284726ad353e"
      },
      "source": [
        "# Statistical methods for data analysis\n",
        "# PHY683\n",
        "### October 16, 2024\n",
        "\n",
        "---\n",
        "\n",
        "- There are two exercises; please complete and submit both.\n",
        "- Name your program file with your name for easy identification.\n",
        "- Submit the Python code by 5 PM on November 5th, 2024.\n",
        "- Do not use ChatGPT, as I may ask follow-up questions about the program.\n",
        "- Read up on `iMinuit`.\n",
        "- For questions that require explanation (e.g., 1(b)), you may submit a separate sheet with your written answer.\n",
        "\n",
        "## Exercise 1\n",
        "\n",
        "This exercise concerns maximum-likelihood fitting with the minimization program `MINUIT` using either its Python implementation `iminuit`. The exercise is carried out by modifying and running the program `mlFit.py`.\n",
        "\n",
        "https://github.com/navaneethphysics/PHY683/blob/main/mlFit.py\n",
        "\n",
        "To use python on your own computer, you will need to install the package `iminuit` (should just work with `pip install iminuit`). See:\n",
        "\n",
        "`Minuit` is a minimisation algorithm, read about it: https://pypi.org/project/iminuit/\n",
        "\n",
        "The program provided generates a data sample of 200 values from a PDF that is a mixture of an exponential and a Gaussian:\n",
        "\n",
        "$$\n",
        "f(x;\\ \\theta,\\ \\xi) = \\theta\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}+(1-\\theta)\\frac{1}{\\xi}e^{-x/\\xi}\n",
        "$$\n",
        "\n",
        "The PDF is modified so as to be truncated on the interval $0 ≤ x ≤ x_{\\text{max}}$. The program `Minuit` is used to find the MLEs for the parameters $\\theta$ and $\\xi$, with the other parameters treated here as fixed. You can think of $\\theta$ as representing the fraction of signal events in the sample (the Gaussian component), and the parameter $\\xi$ characterizes the shape of the background (exponential) component.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00ad93cc-f740-4187-b673-5a8c193de3e6",
      "metadata": {
        "id": "00ad93cc-f740-4187-b673-5a8c193de3e6"
      },
      "source": [
        "### 1. (a)\n",
        "By default the program `mlFit.py` fixes the parameters $\\mu$ and $\\sigma$, and treats only $\\theta$ and $\\xi$ as free. By running the program, obtain the following plots:\n",
        "- the fitted pdf with the data;\n",
        "- a “scan” plot of $−\\ln{L}$ versus $\\theta$;\n",
        "- a contour of $\\ln{L} = \\ln{L_{\\text{max}}} −1/2$ in the $(\\theta,\\ \\xi)$ plane;\n",
        "- confidence regions in the $(\\theta,\\ \\xi)$ plane with confidence levels 68.3% and 95%.\n",
        "\n",
        "From the graph of $−\\ln{L}$ versus $\\theta$, show that the standard deviation of $\\hat{\\theta}$ is the same as the value printed out by the program. From the graph of $\\displaystyle \\ln{L} = \\ln{L_{\\text{max}}} − \\frac{1}{2}$, show that the distances from the MLEs to the tangent lines to the contour give the same standard deviations $\\sigma_{\\hat{\\theta}}$ and $\\sigma_{\\hat{\\xi}}$ as printed out by the program."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "088afeb1-9eee-4fba-93d8-89eae8d4c55d",
      "metadata": {
        "id": "088afeb1-9eee-4fba-93d8-89eae8d4c55d"
      },
      "source": [
        "**Ans.:** The contents of the program `mlFit.py` has been copied \"as-is\" in the following code cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ce3104e-e73b-4bc5-892d-57ebc419f13a",
      "metadata": {
        "id": "6ce3104e-e73b-4bc5-892d-57ebc419f13a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import truncexpon\n",
        "from scipy.stats import truncnorm\n",
        "from scipy.stats import chi2\n",
        "import iminuit\n",
        "from iminuit import Minuit\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import container\n",
        "plt.rcParams[\"font.size\"] = 14\n",
        "print(\"iminuit version:\", iminuit.__version__)  # need 2.x\n",
        "\n",
        "# define pdf and generate data\n",
        "np.random.seed(seed=1234567)        # fix random seed\n",
        "theta = 0.2                         # fraction of signal\n",
        "mu = 10.                            # mean of Gaussian\n",
        "sigma = 2.                          # std. dev. of Gaussian\n",
        "xi = 5.                             # mean of exponential\n",
        "xMin = 0.\n",
        "xMax = 20.\n",
        "\n",
        "def f(x, par):\n",
        "    theta   = par[0]\n",
        "    mu      = par[1]\n",
        "    sigma   = par[2]\n",
        "    xi      = par[3]\n",
        "    fs = stats.truncnorm.pdf(x, a=(xMin-mu)/sigma, b=(xMax-mu)/sigma, loc=mu, scale=sigma)\n",
        "    fb = stats.truncexpon.pdf(x, b=(xMax-xMin)/xi, loc=xMin, scale=xi)\n",
        "    return theta*fs + (1-theta)*fb\n",
        "\n",
        "numVal = 200\n",
        "xData = np.empty([numVal])\n",
        "for i in range (numVal):\n",
        "    r = np.random.uniform();\n",
        "    if r < theta:\n",
        "        xData[i] = stats.truncnorm.rvs(a=(xMin-mu)/sigma, b=(xMax-mu)/sigma, loc=mu, scale=sigma)\n",
        "    else:\n",
        "        xData[i] = stats.truncexpon.rvs(b=(xMax-xMin)/xi, loc=xMin, scale=xi)\n",
        "\n",
        "# Function to be minimized is negative log-likelihood\n",
        "def negLogL(par):\n",
        "    pdf = f(xData, par)\n",
        "    return -np.sum(np.log(pdf))\n",
        "\n",
        "# Initialize Minuit and set up fit:\n",
        "parin   = np.array([theta, mu, sigma, xi]) # initial values (here = true values)\n",
        "parname = ['theta', 'mu', 'sigma', 'xi']\n",
        "parname_latex = [r'$\\theta$', r'$\\mu$', r'$\\sigma$', r'$\\xi$']\n",
        "parstep = np.array([0.1, 1., 1., 1.])      # initial setp sizes\n",
        "parfix  = [False, True, True, False]       # change these to fix/free parameters\n",
        "parlim  = [(0.,1), (None, None), (0., None), (0., None)]    # set limits\n",
        "m = Minuit(negLogL, parin, name=parname)\n",
        "m.errors = parstep\n",
        "m.fixed = parfix\n",
        "m.limits = parlim\n",
        "m.errordef = 0.5                           # errors from lnL = lnLmax - 0.5\n",
        "\n",
        "# Do the fit, get errors, extract results\n",
        "m.migrad()                                        # minimize -logL\n",
        "MLE = m.values                                    # max-likelihood estimates\n",
        "sigmaMLE = m.errors                               # standard deviations\n",
        "cov = m.covariance                                # covariance matrix\n",
        "rho = m.covariance.correlation()                  # correlation coeffs.\n",
        "\n",
        "print(r\"par index, name, estimate, standard deviation:\")\n",
        "for i in range(m.npar):\n",
        "    if not m.fixed[i]:\n",
        "        print(\"{:4d}\".format(i), \"{:<10s}\".format(m.parameters[i]), \" = \",\n",
        "         \"{:.6f}\".format(MLE[i]), \" +/- \", \"{:.6f}\".format(sigmaMLE[i]))\n",
        "\n",
        "print()\n",
        "print(r\"free par indices, covariance, correlation coeff.:\")\n",
        "for i in range(m.npar):\n",
        "    if not(m.fixed[i]):\n",
        "        for j in range(m.npar):\n",
        "            if not(m.fixed[j]):\n",
        "                print(i, j, \"{:.6f}\".format(cov[i,j]), \"{:.6f}\".format(rho[i,j]))\n",
        "\n",
        "# Plot fitted pdf\n",
        "yMin = 0.\n",
        "yMax = f(0., MLE)*1.1\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "xCurve = np.linspace(xMin, xMax, 100)\n",
        "yCurve = f(xCurve, MLE)\n",
        "plt.plot(xCurve, yCurve, color='dodgerblue')\n",
        "plt.xlabel(r'$x$')\n",
        "plt.ylabel(r'$f(x)$')\n",
        "y_fitval = 0.8\n",
        "delta_y_fitval = 0.08\n",
        "plt.figtext(0.6, y_fitval, 'Maximum Likelihood')\n",
        "for i in range(len(parin)):\n",
        "    if not parfix[i]:\n",
        "        y_fitval -= delta_y_fitval\n",
        "        plt.figtext(0.6, y_fitval, parname_latex[i] + ' = ' + f'{MLE[i]:.4f}' + r'$\\pm$' + f'{sigmaMLE[i]:.4f}')\n",
        "\n",
        "# Plot data as tick marks\n",
        "tick_height = 0.05*(yMax - yMin)\n",
        "xvals = [xData, xData]\n",
        "yvals = [np.zeros_like(xData), tick_height * np.ones_like(xData)]\n",
        "plt.plot(xvals, yvals, color='black', linewidth=1)\n",
        "plt.xlim(xMin, xMax)\n",
        "plt.ylim(yMin, yMax)\n",
        "plt.show()\n",
        "\n",
        "# Make scan of lnL (for theta, if free)\n",
        "if not(m.fixed['theta']):\n",
        "    plt.figure()\n",
        "    m.draw_mnprofile('theta')\n",
        "    plt.show()\n",
        "\n",
        "# Make a contour plot of lnL = lnLmax - 1/2 (here for theta and xi).\n",
        "# The tangents to this contour give the standard deviations.\n",
        "CL = stats.chi2.cdf(1.,2)            #  Q_alpha = 1, npar = 2\n",
        "print('CL = ', CL)\n",
        "if not(m.fixed['theta'] | m.fixed['xi']):\n",
        "    fig, ax = plt.subplots(1,1)\n",
        "    con = m.mncontour('theta', 'xi', cl=CL, size=200)\n",
        "    con = np.vstack([con, con[0]])         # close contour\n",
        "    plt.plot(MLE[0], MLE[3], marker='o', linestyle='None', color='black', label=r'$(\\hat{\\theta}, \\hat{\\xi})$')\n",
        "    plt.plot(con[:,0], con[:,1], color='black', linewidth=1)\n",
        "    plt.xlabel(r'$\\theta$', labelpad=5)\n",
        "    plt.ylabel(r'$\\xi$', labelpad=5)\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    plt.legend(handles, labels, loc='upper right', fontsize=14, frameon=False)\n",
        "    plt.figtext(0.4, 0.93, r'$\\ln L = \\ln L_{\\rm max} - 1/2$')\n",
        "    plt.show()\n",
        "\n",
        "# Confidence region from lnL = lnLmax - Q/2 (here for theta and xi)\n",
        "# where Q is the chi2 quantile of CL = 1-alpha = 0.683 and 0.95 for 2 dof.\n",
        "if not(m.fixed['theta'] | m.fixed['xi']):\n",
        "    fig, ax = plt.subplots(1,1)\n",
        "    m.draw_mncontour('theta', 'xi', cl=[0.683, 0.95], size=200);\n",
        "    plt.plot(MLE[0], MLE[3], marker='o', linestyle='None', color='black', label=r'$(\\hat{\\theta}, \\hat{\\xi})$')\n",
        "    plt.xlabel(r'$\\theta$', labelpad=10)\n",
        "    plt.ylabel(r'$\\xi$', labelpad=10)\n",
        "    plt.subplots_adjust(left=0.2, right=0.9, top=0.9, bottom=0.2)\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    plt.legend(handles, labels, loc='upper right', fontsize=14, frameon=False)\n",
        "    plt.figtext(0.3, 0.93, r'$\\ln L = \\ln L_{\\rm max} - \\frac{1}{2} F^{-1}_{\\chi^2}(1-\\alpha;N)$')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d87967e6-ad33-4074-9f74-3666cf3ae9d5",
      "metadata": {
        "id": "d87967e6-ad33-4074-9f74-3666cf3ae9d5"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "385bbf4e-c3fd-424b-95f4-d122931ed0d2",
      "metadata": {
        "id": "385bbf4e-c3fd-424b-95f4-d122931ed0d2"
      },
      "source": [
        "## Conclusion\n",
        "This notebook covered various aspects of maximum-likelihood fitting and data generation using Python. The results obtained were in line with theoretical expectations, and the fitting procedure demonstrated the utility of MLE for parameter estimation.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}